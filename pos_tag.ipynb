{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day. The writer has no idea what topic the random paragraph will be about when it appears. This forces the writer to use creativity to complete one of three common writing challenges. The writer can use the paragraph as the first one of a short story and build upon it. A second option is to use the random paragraph somewhere in a short story they create. The third option is to have the random paragraph be the ending paragraph in a short story. No matter which of these challenges is undertaken, the writer is forced to use creativity to incorporate the paragraph into their writing.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances= nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\AMZ PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Generating', 'VBG'), ('random', 'NN'), ('paragraphs', 'FW'), ('excellent', 'JJ'), ('way', 'NN'), ('writers', 'NNS'), ('get', 'VBP'), ('creative', 'JJ'), ('flow', 'NN'), ('going', 'VBG'), ('beginning', 'VBG'), ('day', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('writer', 'NN'), ('idea', 'NN'), ('topic', 'NN'), ('random', 'NN'), ('paragraph', 'NN'), ('appears', 'VBZ'), ('.', '.')]\n",
      "[('This', 'DT'), ('forces', 'NNS'), ('writer', 'NN'), ('use', 'VBP'), ('creativity', 'NN'), ('complete', 'JJ'), ('one', 'CD'), ('three', 'CD'), ('common', 'JJ'), ('writing', 'VBG'), ('challenges', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('writer', 'NN'), ('use', 'NN'), ('paragraph', 'NN'), ('first', 'RB'), ('one', 'CD'), ('short', 'JJ'), ('story', 'NN'), ('build', 'JJ'), ('upon', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('second', 'JJ'), ('option', 'NN'), ('use', 'NN'), ('random', 'NN'), ('paragraph', 'NN'), ('somewhere', 'RB'), ('short', 'JJ'), ('story', 'NN'), ('create', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('third', 'JJ'), ('option', 'NN'), ('random', 'NN'), ('paragraph', 'NN'), ('ending', 'VBG'), ('paragraph', 'JJ'), ('short', 'JJ'), ('story', 'NN'), ('.', '.')]\n",
      "[('No', 'DT'), ('matter', 'NN'), ('challenges', 'VBZ'), ('undertaken', 'RB'), (',', ','), ('writer', 'RB'), ('forced', 'VBN'), ('use', 'NN'), ('creativity', 'NN'), ('incorporate', 'VBP'), ('paragraph', 'NN'), ('writing', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentances)):\n",
    "    words= nltk.word_tokenize(sentances[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words('english')) ]\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Taj', 'NNP'), ('mahal', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('monument', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "sentanc= nltk.word_tokenize(\"Taj mahal is a beautiful monument\")\n",
    "tagged_sentance = nltk.pos_tag_sents([sentanc])\n",
    "print(tagged_sentance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
